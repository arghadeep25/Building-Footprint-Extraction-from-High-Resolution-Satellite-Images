{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inria_Building_Dataset_Segmentation_with_DeepUNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzA9epqzSE4",
        "colab_type": "text"
      },
      "source": [
        "#Load from ZIP file#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DLx9lS9yuYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip dummy_Inria_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj-2OHyVzf2r",
        "colab_type": "text"
      },
      "source": [
        "#Deep UNet#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inqIhNyqWq9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e71659ac-ea87-470b-ab23-0ceb96c3035f"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as keras\n",
        "from skimage.transform import resize\n",
        "from keras.utils import plot_model, Sequence\n",
        "import keras.backend.tensorflow_backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.layers import Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate\n",
        "from skimage.transform import resize, rotate, rescale, warp, AffineTransform\n",
        "\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Deconvolution2D, Cropping2D\n",
        "from keras.layers import Input, Add, Dropout, Permute, add"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLUmDDhgWvqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataAugmentation():\n",
        "    \"\"\" Class for data augmentation.\n",
        "\n",
        "        Mainly helps when the training data is small\n",
        "\n",
        "        Parameters: image, mask,\n",
        "                    rotation angle (default = 90)\n",
        "                    zoom_range (default = 1)\n",
        "                    horizontal_flip (default = False)\n",
        "                    vertical_flip (default = False)\n",
        "                    activate (default = False)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, image, mask,\n",
        "                rotation = 0,\n",
        "                zoom_range = 1,\n",
        "                horizontal_flip = False,\n",
        "                vertical_flip = False,\n",
        "                shear = 0,\n",
        "                activate = False):\n",
        "\n",
        "        self.image = image\n",
        "        self.mask = mask\n",
        "        self.rotation = rotation\n",
        "        self.zoom_range = zoom_range\n",
        "        self.horizontal_flip = horizontal_flip\n",
        "        self.vertical_flip = vertical_flip\n",
        "        self.shear = shear\n",
        "        self.activate = activate\n",
        "\n",
        "    def rotate_data(self):\n",
        "        \"\"\" Rotation\n",
        "        \"\"\"\n",
        "        self.image = rotate(self.image, self.rotation)\n",
        "        self.mask = rotate(self.mask, self.rotation)\n",
        "        return self.image, self.mask\n",
        "\n",
        "    def rescale_data(self):\n",
        "        \"\"\" Rescaling\n",
        "        \"\"\"\n",
        "        height, width, _ = self.image.shape\n",
        "        self.image = rescale(self.image, self.zoom_range)\n",
        "        self.image = resize(self.image, (height, width))\n",
        "\n",
        "        self.mask = rescale(self.mask, self.zoom_range)\n",
        "        self.mask = resize(self.mask, (height, width))\n",
        "        return self.image, self.mask\n",
        "\n",
        "    def flip_horizontal_data(self):\n",
        "        \"\"\" Flip Horizontally\n",
        "        \"\"\"\n",
        "        if self.horizontal_flip == True:\n",
        "            flipped_image = np.flip(self.image, 1)\n",
        "            flipped_mask = np.flip(self.mask, 1)\n",
        "            return flipped_image, flipped_mask\n",
        "\n",
        "    def flip_vertically_data(self):\n",
        "        \"\"\" Flip Vertically\n",
        "        \"\"\"\n",
        "        if self.vertical_flip == True:\n",
        "            flipped_image = np.flip(self.image, 0)\n",
        "            flipped_mask = np.flip(self.mask, 0)\n",
        "            return flipped_image, flipped_mask\n",
        "\n",
        "    def shear_data(self):\n",
        "        \"\"\" Shear\n",
        "        \"\"\"\n",
        "        trans = AffineTransform(shear = 0.2)\n",
        "        self.image = warp(self.image, inverse_map= trans)\n",
        "        self.mask = warp(self.mask, inverse_map= trans)\n",
        "        return self.image, self.mask\n",
        "\n",
        "    def augment(self):\n",
        "        if self.activate == True:\n",
        "            images = []\n",
        "            masks = []\n",
        "            images.append(self.image)\n",
        "            masks.append(self.mask)\n",
        "            # print('Augmentation:: Image List Size: ',len(images))\n",
        "            if self.rotation != 0:\n",
        "                self.image, self.mask = self.rotate_data()\n",
        "                images.append(self.image)\n",
        "                masks.append(self.mask)\n",
        "\n",
        "            if self.zoom_range != 1:\n",
        "                self.image, self.mask = self.rescale_data()\n",
        "                images.append(self.image)\n",
        "                masks.append(self.mask)\n",
        "\n",
        "            if self.horizontal_flip == True:\n",
        "                self.image, self.mask = self.flip_horizontal_data()\n",
        "                images.append(self.image)\n",
        "                masks.append(self.mask)\n",
        "\n",
        "            if self.vertical_flip == True:\n",
        "                self.image, self.mask = self.flip_vertically_data()\n",
        "                images.append(self.image)\n",
        "                masks.append(self.mask)\n",
        "\n",
        "            if self.shear != 0:\n",
        "                self.image, self.mask = self.shear_data()\n",
        "                images.append(self.image)\n",
        "                masks.append(self.mask)\n",
        "        else:\n",
        "            images = []\n",
        "            masks = []\n",
        "            images.append(self.image)\n",
        "            masks.append(self.mask)\n",
        "\n",
        "        images = np.array(images)\n",
        "        masks = np.array(masks)\n",
        "\n",
        "        return images, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipPFNYFABIyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class InriaDataLoader(Sequence):\n",
        "    \"\"\" Load the training dataset for Inria Dataset from the\n",
        "        data folder and put in an array\n",
        "\n",
        "        Parameters: - data_path: Loads the datapath\n",
        "                    - patch_size: Format the image sizes (default: 256x256)\n",
        "                    - train_ids:\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, data_ids, data_path, patch_size = 256,\n",
        "                batch_size = 8, aug = False, rotation = 0,\n",
        "                zoom_range = 1, horizontal_flip = False,\n",
        "                vertical_flip = False, shear = 0):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.data_ids = data_ids\n",
        "        self.patch_size = patch_size\n",
        "        self.batch_size = batch_size\n",
        "        self.aug = aug\n",
        "        self.rotation = rotation\n",
        "        self.zoom_range = zoom_range\n",
        "        self.horizontal_flip = horizontal_flip\n",
        "        self.vertical_flip = vertical_flip\n",
        "        self.shear = shear\n",
        "\n",
        "    def __load__(self, data_name):\n",
        "        \"\"\" Load an image and a mask from the data folder\n",
        "            Parameters: Image name\n",
        "        \"\"\"\n",
        "        image_name_path = os.path.join(self.data_path,'images/', data_name)\n",
        "        mask_name_path = os.path.join(self.data_path, 'gt', data_name)\n",
        "\n",
        "        image = cv2.imread(image_name_path, 1)\n",
        "        image = cv2.resize(image, (self.patch_size,\n",
        "                            self.patch_size))\n",
        "\n",
        "        mask = cv2.imread(mask_name_path)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = cv2.resize(mask, (self.patch_size,\n",
        "                            self.patch_size))\n",
        "        mask = mask[:, :, np.newaxis]\n",
        "\n",
        "        image = image/255.\n",
        "        \n",
        "        mask = mask/255.\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Get all the images and masks in the data folder\n",
        "            and put into array\n",
        "        \"\"\"\n",
        "        if(index+1)*self.batch_size > len(self.data_ids):\n",
        "            self.batch_size = len(self.data_ids) - index*self.batch_size\n",
        "\n",
        "        files_batch = self.data_ids[index * \\\n",
        "            self.batch_size: (index + 1) * self.batch_size]\n",
        "\n",
        "        images = []\n",
        "        masks = []\n",
        "\n",
        "        for file in files_batch:\n",
        "            image, mask = self.__load__(file)\n",
        "    \n",
        "            aug = DataAugmentation(image, mask,\n",
        "                                   rotation =self.rotation,\n",
        "                                   zoom_range = self.zoom_range,\n",
        "                                   horizontal_flip = self.horizontal_flip,\n",
        "                                   vertical_flip = self.vertical_flip,\n",
        "                                   activate = self.aug)\n",
        "\n",
        "            aug_images, aug_masks = aug.augment()\n",
        "\n",
        "            for aug_image in aug_images:\n",
        "                images.append(aug_image)\n",
        "\n",
        "            for aug_mask in aug_masks:\n",
        "                masks.append(aug_mask)\n",
        "              \n",
        "\n",
        "        images = np.array(images)\n",
        "        masks = np.array(masks)\n",
        "\n",
        "        return images, masks\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data_ids)/float(self.batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seJU3ptRBK41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Visualizer():\n",
        "    \"\"\" Class for visualizing input image and corresponding\n",
        "        mask\n",
        "\n",
        "        Parameters: image\n",
        "                    mask\n",
        "    \"\"\"\n",
        "    def __init__(self, image, mask, image_size = 256):\n",
        "        self.image = image\n",
        "        self.mask = mask\n",
        "        self.image_size = image_size\n",
        "\n",
        "    def plot(self):\n",
        "        fig = plt.figure()\n",
        "        fig.subplots_adjust(hspace = 0.4, wspace = 0.4)\n",
        "\n",
        "        fig_a = fig.add_subplot(1, 2, 1)\n",
        "        fig_a.set_title('Input Image')\n",
        "        image = np.reshape(self.image[0]*255, \n",
        "                           (self.image_size, self.image_size))\n",
        "        plt.imshow(image)\n",
        "\n",
        "        fig_b = fig.add_subplot(1, 2, 2)\n",
        "        fig_b.set_title('Output Mask')\n",
        "        mask = np.reshape(self.mask[0]*255, \n",
        "                          (self.image_size, self.image_size))\n",
        "        plt.imshow(mask)\n",
        "\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ppkZzv9CgjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda, Activation\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Add\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# def dice_coef(y_true, y_pred):\n",
        "#     return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
        "class DeepUNet():\n",
        "    \"\"\" Deep U-Net Model\n",
        "\n",
        "        Parameters: - Image Size (default = 256)\n",
        "                    - Kernel Size (default = (3, 3))\n",
        "                    - Padding (default = 'same')\n",
        "                    - Activation (default = 'relu')\n",
        "                    - Pool Size (default = 2)\n",
        "                    - Strides (default = 1)\n",
        "                    - Max Pool Strides (default = 2)\n",
        "                    - Up Sample (default = 2)\n",
        "    \"\"\"\n",
        "    def __init__(self, image_size=256,\n",
        "                 kernel_size=(3,3),\n",
        "                 padding='same',\n",
        "                 activation='relu',\n",
        "                 pool_size=2,\n",
        "                 strides=1,\n",
        "                 max_pool_strides=2,\n",
        "                 up_sample=2):\n",
        "        self.image_size = image_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.activation = activation\n",
        "        self.pool_size = pool_size\n",
        "        self.strides = strides\n",
        "        self.max_pool_strides = max_pool_strides\n",
        "        self.up_sample = up_sample\n",
        "\n",
        "    def network(self):\n",
        "        # filters\n",
        "        f = [16, 32, 64, 128, 256]\n",
        "        # inputs\n",
        "        inputs = Input((self.image_size, self.image_size, 3))\n",
        "\n",
        "        # Encoder\n",
        "        conv1 = Conv2D(f[0],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=self.strides)(inputs)\n",
        "        bn1 = BatchNormalization()(conv1)\n",
        "        act1 = Activation(self.activation)(bn1)\n",
        "\n",
        "        conv2 = Conv2D(f[0],\n",
        "                       kernel_size=(1,1),\n",
        "                       padding=self.padding,\n",
        "                       strides=self.strides)(inputs)\n",
        "        bn2 = BatchNormalization()(conv2)\n",
        "\n",
        "        sum1 = Add()([act1, bn2])\n",
        "\n",
        "        # residaul block 1\n",
        "        bn3 = BatchNormalization()(sum1)\n",
        "        act3 = Activation(self.activation)(bn3)\n",
        "        conv3 = Conv2D(f[1],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=2)(act3)\n",
        "        bn4 = BatchNormalization()(conv3)\n",
        "        act4 = Activation(self.activation)(bn4)\n",
        "        conv4 = Conv2D(f[1],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=1)(act4)\n",
        "        conv5 = Conv2D(f[1],\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding=self.padding,\n",
        "                       strides=2)(sum1)\n",
        "        bn5 = BatchNormalization()(conv5)\n",
        "\n",
        "        sum2 = Add()([bn5, conv4])\n",
        "\n",
        "        # residual block 2\n",
        "        bn6 = BatchNormalization()(sum2)\n",
        "        act6 = Activation(self.activation)(bn6)\n",
        "        conv6 = Conv2D(f[2],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=2)(act6)\n",
        "        bn7 = BatchNormalization()(conv6)\n",
        "        act7 = Activation(self.activation)(bn7)\n",
        "        conv7 = Conv2D(f[2],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=1)(act7)\n",
        "        conv8 = Conv2D(f[2],\n",
        "                       kernel_size=(1, 1),\n",
        "                       padding=self.padding,\n",
        "                       strides=2)(sum2)\n",
        "        bn8 = BatchNormalization()(conv8)\n",
        "\n",
        "        sum3 = Add()([bn8, conv7])\n",
        "\n",
        "        # residual block 3\n",
        "        bn9 = BatchNormalization()(sum3)\n",
        "        act9 = Activation(self.activation)(bn9)\n",
        "        conv9 = Conv2D(f[3],\n",
        "                       kernel_size=self.kernel_size,\n",
        "                       padding=self.padding,\n",
        "                       strides=2)(act9)\n",
        "        bn10 = BatchNormalization()(conv9)\n",
        "        act10 = Activation(self.activation)(bn10)\n",
        "        conv10 = Conv2D(f[3],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act10)\n",
        "        conv11 = Conv2D(f[3],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=2)(sum3)\n",
        "        bn11 = BatchNormalization()(conv11)\n",
        "\n",
        "        sum4 = Add()([bn11, conv10])\n",
        "\n",
        "        # residual block 4\n",
        "        bn12 = BatchNormalization()(sum4)\n",
        "        act12 = Activation(self.activation)(bn12)\n",
        "        conv12 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=2)(act12)\n",
        "        bn13 = BatchNormalization()(conv12)\n",
        "        act13 = Activation(self.activation)(bn13)\n",
        "        conv13 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act13)\n",
        "        conv14 = Conv2D(f[4],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=2)(sum4)\n",
        "        bn14 = BatchNormalization()(conv14)\n",
        "\n",
        "        sum5 = Add()([bn14, conv13])\n",
        "\n",
        "        # Bridge\n",
        "        bn15 = BatchNormalization()(sum5)\n",
        "        act15 = Activation(self.activation)(bn15)\n",
        "        conv15 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act15)\n",
        "\n",
        "        bn16 = BatchNormalization()(conv15)\n",
        "        act16 = Activation(self.activation)(bn16)\n",
        "        conv16 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act16)\n",
        "\n",
        "        # Decoder\n",
        "        # decode block 1\n",
        "        us1 = UpSampling2D((2, 2))(conv16)\n",
        "        conc1 = Concatenate()([us1, sum4])\n",
        "\n",
        "        bn17 = BatchNormalization()(conc1)\n",
        "        act17 = Activation(self.activation)(bn17)\n",
        "        conv17 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act17)\n",
        "        bn18 = BatchNormalization()(conv17)\n",
        "        act18 = Activation(self.activation)(bn18)\n",
        "        conv18 = Conv2D(f[4],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act18)\n",
        "        conv19 = Conv2D(f[4],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(sum4)\n",
        "        bn19 = BatchNormalization()(conv19)\n",
        "\n",
        "        sum6 = Add()([bn19, conv18])\n",
        "\n",
        "        # decode block 2\n",
        "        us2 = UpSampling2D((2, 2))(sum6)\n",
        "        conc2 = Concatenate()([us2, sum3])\n",
        "\n",
        "        bn20 = BatchNormalization()(conc2)\n",
        "        act20 = Activation(self.activation)(bn20)\n",
        "        conv20 = Conv2D(f[3],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act20)\n",
        "        bn21 = BatchNormalization()(conv20)\n",
        "        act21 = Activation(self.activation)(bn21)\n",
        "        conv21 = Conv2D(f[3],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act21)\n",
        "        conv22 = Conv2D(f[3],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(sum3)\n",
        "        bn22 = BatchNormalization()(conv22)\n",
        "\n",
        "        sum7 = Add()([bn22, conv21])\n",
        "\n",
        "        # decode block 3\n",
        "        us3 = UpSampling2D((2, 2))(sum7)\n",
        "        conc3 = Concatenate()([us3, sum2])\n",
        "\n",
        "        bn23 = BatchNormalization()(conc3)\n",
        "        act23 = Activation(self.activation)(bn23)\n",
        "        conv23 = Conv2D(f[2],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act23)\n",
        "        bn24 = BatchNormalization()(conv23)\n",
        "        act24 = Activation(self.activation)(bn24)\n",
        "        conv24 = Conv2D(f[2],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act24)\n",
        "        conv25 = Conv2D(f[2],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(sum2)\n",
        "        bn25 = BatchNormalization()(conv25)\n",
        "\n",
        "        sum8 = Add()([bn25, conv24])\n",
        "\n",
        "        # decode block 4\n",
        "        us4 = UpSampling2D((2, 2))(sum8)\n",
        "        conc4 = Concatenate()([us4, sum1])\n",
        "\n",
        "        bn26 = BatchNormalization()(conc4)\n",
        "        act26 = Activation(self.activation)(bn26)\n",
        "        conv26 = Conv2D(f[1],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act26)\n",
        "        bn27 = BatchNormalization()(conv26)\n",
        "        act27 = Activation(self.activation)(bn27)\n",
        "        conv27 = Conv2D(f[1],\n",
        "                        kernel_size=self.kernel_size,\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(act27)\n",
        "        conv28 = Conv2D(f[1],\n",
        "                        kernel_size=(1, 1),\n",
        "                        padding=self.padding,\n",
        "                        strides=1)(sum1)\n",
        "        bn28 = BatchNormalization()(conv28)\n",
        "\n",
        "        sum9 = Add()([bn28, conv27])\n",
        "\n",
        "        # Final Layer\n",
        "        outputs = Conv2D(1,\n",
        "                         kernel_size=(1, 1),\n",
        "                         padding=\"same\",\n",
        "                         activation=\"sigmoid\")(sum9)\n",
        "        model = Model(inputs, outputs)\n",
        "        return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqcxwvKNCjA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"\"\"\n",
        "# Name: Train U-Net Model\n",
        "# Author: Arghadeep Mazumder\n",
        "# Version: 0.1\n",
        "# Description: Train U-Net Model\n",
        "\n",
        "# \"\"\"\n",
        "# import os\n",
        "# import sys\n",
        "# import cv2\n",
        "# import keras.utils\n",
        "# import numpy as np\n",
        "# sys.path.append('../')\n",
        "# from utils.iou import IoU\n",
        "# from models.fcn import FCN\n",
        "# from utils.loader import InriaDataLoader\n",
        "# from keras.models import Model\n",
        "# from keras.layers import *\n",
        "# from keras.optimizers import *\n",
        "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "# from keras import backend as keras\n",
        "# from utils.visualizer import InriaVisualizer\n",
        "\n",
        "class TrainDeepUNet():\n",
        "    \"\"\" Class for training U-Net Model\n",
        "\n",
        "        Parameters: train_path       = train folder\n",
        "                    patch_size      = 256\n",
        "                    activate_aug    = False\n",
        "                    rotation        = 0\n",
        "                    zoom_range      = 1\n",
        "                    horizontal_flip = False\n",
        "                    vertical_flip   = False\n",
        "                    shear           = 0\n",
        "                    net             = U-Net\n",
        "                    epochs          = 5\n",
        "                    batch_size      = 1\n",
        "                    learning_rate   = 0.2\n",
        "                    val_percent     =\n",
        "                    save_model      = False\n",
        "                    activate_gpu    = False\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                train_path,\n",
        "                image_size = 256,\n",
        "                activate_aug = False,\n",
        "                rotation = 0,\n",
        "                zoom_range = 1,\n",
        "                horizontal_flip = False,\n",
        "                vertical_flip = False,\n",
        "                shear = 0,\n",
        "                epochs = 10,\n",
        "                batch_size = 8,\n",
        "                learning_rate = 0.1,\n",
        "                save_model = True,\n",
        "                val_data_size = 10,\n",
        "                evaluate = True):\n",
        "\n",
        "        self.train_path = train_path\n",
        "        self.image_size = image_size\n",
        "        self.activate_aug = activate_aug\n",
        "        self.rotation = rotation\n",
        "        self.zoom_range = zoom_range\n",
        "        self.horizontal_flip = horizontal_flip\n",
        "        self.vertical_flip = vertical_flip\n",
        "        self.shear = shear\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.save_model = save_model\n",
        "        self.val_data_size = val_data_size\n",
        "        self.evaluate = evaluate\n",
        "\n",
        "    def train(self):\n",
        "        print('''\n",
        "Start Training:\n",
        "\n",
        "    Data Path:       {}\n",
        "    Model:           {}\n",
        "    Patch Size:      {}\n",
        "    Augmentation:    {}\n",
        "    Rotation:        {}\n",
        "    Zoom Range:      {}\n",
        "    Horizontal Flip: {}\n",
        "    Vertical Flip:   {}\n",
        "    Shear:           {}\n",
        "    Epochs:          {}\n",
        "    Batch Size:      {}\n",
        "    Learning Rate:   {}\n",
        "    Validation %:    {}\n",
        "    Save Model:      {}\n",
        "    Evaluate:        {}\n",
        "\n",
        "        '''.format(str(self.train_path), str('U-Net'), self.image_size,\n",
        "            self.activate_aug, self.rotation, self.zoom_range,\n",
        "            self.horizontal_flip, self.vertical_flip, self.shear,\n",
        "            self.epochs, self.batch_size, self.learning_rate,\n",
        "            self.val_data_size, self.save_model, self.evaluate))\n",
        "\n",
        "        images_path = os.path.join(self.train_path, 'images/')\n",
        "        train_ids = next(os.walk(images_path))[2]\n",
        "\n",
        "        valid_ids = train_ids[:self.val_data_size]\n",
        "        train_ids = train_ids[self.val_data_size:]\n",
        "\n",
        "\n",
        "        models = DeepUNet()\n",
        "        model = models.network()\n",
        "        model.compile(optimizer = 'adam',\n",
        "                    loss = 'binary_crossentropy',\n",
        "                    metrics = ['acc'])\n",
        "        model.summary()\n",
        "\n",
        "        train_gen = InriaDataLoader(train_ids,\n",
        "                                    self.train_path,\n",
        "                                    patch_size = self.image_size,\n",
        "                                    batch_size = self.batch_size)\n",
        "\n",
        "        valid_gen = InriaDataLoader(valid_ids,\n",
        "                                    self.train_path,\n",
        "                                    patch_size = self.image_size,\n",
        "                                    batch_size = self.batch_size)\n",
        "\n",
        "        train_steps = len(train_ids) // self.batch_size\n",
        "        valid_steps = len(valid_ids) // self.batch_size\n",
        "        print(train_steps)\n",
        "        model.fit_generator(train_gen,\n",
        "                            validation_data = valid_gen,\n",
        "                            steps_per_epoch = train_steps,\n",
        "                            validation_steps = valid_steps,\n",
        "                            epochs = self.epochs)\n",
        "        if self.save_model:\n",
        "            model.save('building_deepunet.h5')\n",
        "\n",
        "#         keras.utils.plot_model(model, to_file = 'unet_architecture.png')\n",
        "\n",
        "        if self.evaluate:\n",
        "            image , mask = valid_gen.__getitem__(2)\n",
        "            result = model.predict(image)\n",
        "            result = result > 0.5\n",
        "            viz = Visualizer(mask, result)\n",
        "            viz.plot()\n",
        "\n",
        "#         iou_score = IoU(target= mask, prediction=result)\n",
        "#         print('IoU Score: ',iou_score)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSFQ_l-bC0tT",
        "colab_type": "code",
        "outputId": "55891a6b-7141-48e9-995b-cd7c4c9633dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_fcn = TrainDeepUNet(train_path='dummy_Inria_data/train')\n",
        "train_fcn.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0723 18:13:20.914110 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0723 18:13:20.956295 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0723 18:13:20.963299 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0723 18:13:21.009352 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0723 18:13:21.012181 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start Training:\n",
            "\n",
            "    Data Path:       dummy_Inria_data/train\n",
            "    Model:           U-Net\n",
            "    Patch Size:      256\n",
            "    Augmentation:    False\n",
            "    Rotation:        0\n",
            "    Zoom Range:      1\n",
            "    Horizontal Flip: False\n",
            "    Vertical Flip:   False\n",
            "    Shear:           0\n",
            "    Epochs:          10\n",
            "    Batch Size:      8\n",
            "    Learning Rate:   0.1\n",
            "    Validation %:    10\n",
            "    Save Model:      True\n",
            "    Evaluate:        True\n",
            "\n",
            "        \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0723 18:13:24.216511 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0723 18:13:25.709342 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0723 18:13:26.878841 140245804066688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0723 18:13:26.906870 140245804066688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 256, 256, 16) 448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 16) 64          input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 256, 256, 16) 0           activation_1[0][0]               \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 256, 256, 16) 64          add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 256, 256, 16) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 128, 128, 32) 4640        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 32) 544         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 128, 128, 32) 128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 32) 9248        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 128, 128, 32) 0           batch_normalization_5[0][0]      \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 128, 128, 32) 128         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 128, 32) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   18496       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   2112        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 64, 64, 64)   0           batch_normalization_8[0][0]      \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 64, 64, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 64, 64, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  73856       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 128)  8320        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 256)  295168      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 256)  1024        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 256)  1024        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           batch_normalization_14[0][0]     \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 256)  590080      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 384)  1536        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 384)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 256)  884992      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 256)  33024       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 256)  590080      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 320)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 64, 64, 320)  1280        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 320)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 128)  368768      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 64, 64, 128)  512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 128)  8320        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147584      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 128)  0           batch_normalization_22[0][0]     \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 160 0           up_sampling2d_3[0][0]            \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 128, 128, 160 640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 128, 128, 160 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 128, 128, 64) 92224       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 128, 128, 64) 256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 128, 128, 64) 2112        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 128, 128, 64) 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 128, 128, 64) 256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 128, 64) 36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 128, 128, 64) 0           batch_normalization_25[0][0]     \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 64) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 256, 256, 80) 0           up_sampling2d_4[0][0]            \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 256, 256, 80) 320         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 256, 256, 80) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 256, 256, 32) 23072       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 256, 256, 32) 128         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 256, 256, 32) 544         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 256, 256, 32) 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 256, 256, 32) 128         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 256, 256, 32) 9248        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 256, 256, 32) 0           batch_normalization_28[0][0]     \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 256, 256, 1)  33          add_9[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,612,193\n",
            "Trainable params: 4,604,897\n",
            "Non-trainable params: 7,296\n",
            "__________________________________________________________________________________________________\n",
            "123\n",
            "Epoch 1/10\n",
            "123/123 [==============================] - 37s 300ms/step - loss: 0.2788 - acc: 0.8816 - val_loss: 0.8518 - val_acc: 0.7308\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 22s 180ms/step - loss: 0.2156 - acc: 0.9099 - val_loss: 1.3124 - val_acc: 0.5096\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 22s 175ms/step - loss: 0.1933 - acc: 0.9187 - val_loss: 0.4262 - val_acc: 0.8368\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.1729 - acc: 0.9264 - val_loss: 0.7931 - val_acc: 0.6612\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.1648 - acc: 0.9289 - val_loss: 0.2682 - val_acc: 0.9014\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.1616 - acc: 0.9298 - val_loss: 0.1477 - val_acc: 0.9346\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 0.1422 - acc: 0.9375 - val_loss: 0.2856 - val_acc: 0.8919\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 22s 176ms/step - loss: 0.1297 - acc: 0.9418 - val_loss: 0.1743 - val_acc: 0.9313\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.1210 - acc: 0.9443 - val_loss: 0.1718 - val_acc: 0.9393\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 22s 177ms/step - loss: 0.1172 - acc: 0.9453 - val_loss: 0.1614 - val_acc: 0.9332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAC6CAYAAACgP4aQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF25JREFUeJzt3Xu8VXWd//HXW0DIu6gRIAom9huc\nCokQ7WY/SwQt/E3zMJxMxnyEeZlfTtnE1FjWVDPTI+uhv5/YD9JEu5iVjvSIEYkpzbyBDgLKiAQi\nNyFN8ZbI5fP7Y61ji+M57H32PmuvvRbv5+NxHnud77p91mF/Pnz3d122IgIzM6uuvYoOwMzM8uVC\nb2ZWcS70ZmYV50JvZlZxLvRmZhXnQm9mVnEu9GZmNUgaLikk9S06lka40Hci6QlJH2jBfi6X9IN2\niMWsM0l/K2mppJclPSXpGkkH9WD9Xn3v1tqepJPSQnxrp/a3p+2/6a1YysiF3sx2IemzwL8BnwMO\nBMYDRwLzJe1dZGw1/AE4QdIhmbapwIqC4mkbLvS7kfZq7pb0LUnPSlotaWJm/m8k/YukByQ9L+k2\nSQPTeSdJWtdpe09I+oCkU4EvAB+V9KKkh+uM5XeSviPpOUmrJJ2Ytq+VtFnS1Mzyp0n6rzSutZIu\n77S9cyStkfSMpMuyPSZJe0maLun36fybO47Lqk3SAcBXgL+LiNsjYltEPAGcCQwHzk6Xu17S1zLr\nvfZ+l3QjcATwi/T9/Q+ZoY9pkjZI2ijp0sz6PdpeN+G/Cvw7MCVdrw/wUeCHnY7xyjQnnpf0oKT3\nZOaNk7QonbdJ0re7+Tt9JM2Zv6z9Vy2eC31txwOPAYcC3wSulaTM/HOATwCDge3AVbU2GBG3A98A\nfhIR+0XE23sQyxLgEOBHwE3AO4GjSRLw/0raL132pTS2g4DTgAsknQEgaRQwA/hYGveBwNDMfv4O\nOAN4HzAEeBa4us4YrdxOBAYAt2QbI+JFYC7wwVobiIiPA08CH0rf39/MzH4/MBI4Bfh8PcM7NbbX\n2Q0k73uACcAyYEOnZRYCo4GBJHn0U0kD0nlXAldGxAHAm4GbO+9A0rkkn3g+EBHLasXfDlzoa1sT\nEbMiYgcwm6QwDsrMvzEilkXES8BlwJlpTyIPqyPi+2ksPwGGAV+NiK0RcQdJj+ZogIj4TUQsjYid\nEbEE+DFJ4Qb4a+AXEXF3RLwKfAnIPvToU8AXI2JdRGwFLgf+uqwnoqxHDgWejojtXczbmM5vxlci\n4qWIWAp8Hzirye3tIiLuAQZKegtJwb+hi2V+EBHPRMT2iLgC6A+8JZ29DTha0qER8WJE3Ndp9UtI\nhrROioiVvRl7nlzoa3uqYyIiXk4n98vMX5uZXgP0o/lk6M6mzPSf0pg6t+0HIOl4Sb+W9AdJW0iK\nd0dcQ7Jxp8f1TGY7RwK3pkNEzwHLgR3s+h+cVdPTwKHd/Kc+OJ3fjM75MqTJ7XXlRuBikk8Pt3ae\nKelSScslbUnf3wfy59w4DzgG+G9JCyWd3mn1zwFXR8Q6SsSFvnnDMtNHkPQIniYZOtmnY0bayz8s\ns2zejw39ETAHGBYRBwLfBTqGnDYCh2diewPJcFCHtcDEiDgo8zMgItbnHLMV715gK/BX2cZ0SHAi\nsCBt2uX9Dbyp03a6e393zpeOYZVGt9eVG4ELgbmZzhkA6Xj8P5Ccczg4Ig4CtpDmRkQ8HhFnAW8k\nGZ75maR9M5s4BfgnSR/pQTyFc6Fv3tmSRknaB/gq8LN0aGUFMCA9KdoP+CeSj4gdNgHDJeX1b7A/\n8MeIeEXSOOBvMvN+BnwoPZm7N8nQTPa8w3eBr0s6EkDSYZIm5xSntZGI2EJyMvb/SDpVUj9Jw0nG\nqteRFFGAxcAkSQMlvYlkSCNrE3BUF7u4TNI+ko4FziUZgmxme10dw2qSYcovdjF7f5JzaX8A+kr6\nEnBAx0xJZ0s6LCJ2As+lzTsz6z8CnApcLenD9cTTDlzom3cjcD3JEM8A4H/DawlzIfA9YD1JjyX7\nce+n6eszkh7KIa4Lga9KeoFkDP61k0oR8QjJCdebSHr3LwKbSXpykJyQmgPcka5/H8mJYNsDpCc7\nvwB8C3geuJ/kU97J6TkbSN73DwNPAHfw54Ld4V9Ier7PZa+uAe4EVpJ8MvhWem6pme11dwx3R0Tn\nk7AA84DbSTpia4BX2HU46VTgEUkvkuTBlIj4U6dtPwycDsxS5iq8diZ/8UjjlNyE8YOI+F7RsTQj\n/Vj+HDAy7Q2Z9ar0U8FqoF83J3otR+7R76EkfSj9CL0vSc9tKUlvyswqJrdCn47vPSZppaTpee3H\nGjaZ5ETYBpLrmqeEP97lwrlgRctl6Ca9wmQFyc0V60huUDgrIh7t9Z2ZtTHngrWDvHr044CVEbEq\nvSHnJpIepNmexrlghcvrTseh7Homex27uWpjb/WPAezb3Wwr0DFve7n2Qr1kxZJ9ai8EvMCzT0fE\nYbWXbAs9ygVwPrSzvPOh3hzo8Aov8WpsVa3lCrulXdI0YBrAAPbheJ1cVCjWjRXffwcPTLi2Jfsa\nMWcax3/qgbqW/VX8bE3O4bSc86Ec5s1bnPs+JgwZXfey98eC2guR39DNena9A+7wtO01ETEzIsZG\nxNh+u9xHZO3itydf2bJ9HVNnkS+hmrkAzocymLehvYp8T+RV6BcCIyWNSO+8nEJyA46VxIpZ7+Tw\nvvvVXrBJI375SU5756Tc91Mg54IVLpehm4jYLulikrvQ+gDXpXdjWkmsPm1WS/Yz6hub2b6+qxsY\nq8G5UA2t6M3nKbcx+oiYS/L8aiuZnQuGkTx6JF8j5p3HMasfzH0/RXMuWNF8Z6y9ztePuqX2Qr3g\nDas8Fm3tr1W9+bzG58GF3jp5/MrxjOvfL/f9HDX/Ewz753ty34+ZFXh5pbWfNy8cwLyh323Jvt7y\n7T/t8uxXs3ZUhd48uEdvGTOGdv7WtHwcc+dUdj68vCX7MmtU2U/AZrnQGwBfWdW6k6JHXbGjZfsy\na3d59+bBhd6AtZedyPgBeX2f+a5OuPRTxKJlLdmXWaOq1JsHF3oDvnh25y/zyceYRR/lwMdeaMm+\nzMqgFb15cKE34GP7P9OS/bzxK32JB32vkLW3qpyAzXKh3wOpb182fuZE1G9vZqy5uyX7nLD8dBd5\ns4L48so90O1PLgIWwaUA+T/PBoCT19VexqwgVRuT78w9+j1M36FDWr7PUz4yteX7NKtXEUW+lcM2\n4EK/x/nlwtY/ckX3PtzyfZrVY08o8uBCv0fZa5+efXtNb/ja0/+j5fs0s1250O9B/mNl658t89u3\nDWj5Ps3aVRG9eXCh32PECW9v+T4r/oUiVnKtHrYpqsiDr7rZY9zx89kt3d+SV1+p9BeKmNWjyOKe\n5R591e3Vh1dOH9fSXT6742U+P+p/tnSfZtY99+gr7pXT3sGd/29mS/c55Yh3Qbzc0n2a9USZv+i7\nEe7RW69at/1FiCg6DDPLaKrQS3pC0lJJiyUtStsGSpov6fH09eDeCdUaMeAXDzBhyGhOO/HDLdnf\n+e85qyX7aUfOh/LIu7fdTr156J0e/fsjYnREjE1/nw4siIiRwIL0dyvY9iee5NQjx3Hy2eflto/f\nvbKT7WvW5rb9knA+lERexbgVRX7ehsU9Gn7KY+hmMtBxicds4Iwc9mENiG2v0vc/H2TC0OP44EfP\nZfOOl3p1+189akyvbq8inA97iAlDRre8J3/M2+o7F9ZsoQ/gDkkPSpqWtg2KiI3p9FPAoK5WlDRN\n0iJJi7axtckwrEci2Ou3/8XHh72Lkz75yV7Z5A9fOKRXtlNyzoeS6a3i3MoC38iJ5GYL/bsjYgww\nEbhI0nuzMyMiSN78rxMRMyNibESM7Uf/JsOwRvX/5ULec/H5TW/ne5/+q16IpvScDyXVbmPqva2p\nQh8R69PXzcCtwDhgk6TBAOnr5maDtHztc8v9TBgymqufG9bQ+t94+i3sffvCXo6qfJwP5dZo774M\n/0k0XOgl7Stp/45p4BRgGTAH6Hgu7VTgtmaDtNaYM+oQJgwZzXFfu7BH6935tjfkFFF5OB+qoycF\nvwxFHpq7YWoQcKukju38KCJul7QQuFnSecAa4Mzmw7RWeuOMe5gwYzRH3L8vs4b9brfLXrh+PPBK\nawJrb86HiskW8a7GxYso8o3e6NVwoY+IVcDrnpQVEc8AJze6XWsfTx7/Eu89YxqHfmY1txw9/3Xz\nx375Ag6ZdW8BkbUf50O1dS76ZenJd/CdsbZbb/j3B3jpvX/gfedP4/QVE19rn7lliIu87ZGKLPKd\nh5VWLKnvOyZc6K0uA37xAC9+83AmLD8dgJ9ueEfBEZntuXp64tgPNbO69Z+7EObCB97/Cfr8+qGi\nwzGzOrlHbz3mIm9WLi70ZmYV50JvZlZxLvRmZhXnQm9mVnEu9GZmFedCb2ZWcS70ZmYV50JvZlZx\nLvRmZhXnQm9mVnEu9GZmFedCb2ZWcS70ZmYV50JvZlZxNQu9pOskbZa0LNM2UNJ8SY+nrwen7ZJ0\nlaSVkpZIGpNn8Gat5nywMqqnR389cGqntunAgogYCSxIfweYCIxMf6YB1/ROmGZt43qcD1YyNQt9\nRNwF/LFT82Rgdjo9Gzgj035DJO4DDpI0uLeCNSua88HKqNEx+kERsTGdfgoYlE4PBdZmlluXtr2O\npGmSFklatI2tDYZh1hacD9bWmj4ZGxEBRAPrzYyIsRExth/9mw3DrC04H6wdNVroN3V8BE1fN6ft\n64FhmeUOT9vMqsz5YG2t0UI/B5iaTk8Fbsu0n5NebTAe2JL5SGtWVc4Ha2t9ay0g6cfAScChktYB\nXwb+FbhZ0nnAGuDMdPG5wCRgJfAycG4OMZsVxvlgZVSz0EfEWd3MOrmLZQO4qNmgzNqV88HKyHfG\nmplVnAu9mVnFudCbmVWcC72ZWcW50JuZVZwLvZlZxbnQm5lVnAu9mVnFudCbmVWcC72ZWcW50JuZ\nVZwLvZlZxbnQm5lVnAu9mVnFudCbmVWcC72ZWcW50JuZVZwLvZlZxdUs9JKuk7RZ0rJM2+WS1kta\nnP5Mysz7R0krJT0maUJegZsVwflgZVRPj/564NQu2r8TEaPTn7kAkkYBU4Bj03VmSOrTW8FaeayY\nMY4V3x1XdBh5uB7ng5VMPV8Ofpek4XVubzJwU0RsBVZLWgmMA+5tOEIrnd9fMZ5HPnwV++y1N3wY\nTjv+dLavXVd0WL3C+WCNmrdh8WvTE4aMbum+mxmjv1jSkvSj7MFp21BgbWaZdWnb60iaJmmRpEXb\n2NpEGNZuHpsyIynyqUcvfxN9jh5RYEQt4XywbmWLfFe/563RQn8N8GZgNLARuKKnG4iImRExNiLG\n9qN/g2FYu+lz0IH00a5vq9UTv8fcu27l8dljWHvZiQVFlivng3Wru6I+b8PilhX8hgp9RGyKiB0R\nsROYRfJxFGA9MCyz6OFpm+0h5j56Z7fzVn3wOh69YAbzNixm42eqU/CdD9aMVhT7hgq9pMGZX/8X\n0HEFwhxgiqT+kkYAI4EHmgvRymLD5+ov3ksuncGam9+K3vnWHCNqDeeDdafeIp53777myVhJPwZO\nAg6VtA74MnCSpNFAAE8A5wNExCOSbgYeBbYDF0XEjnxCt3bS54ADWPr3M3q0zn+/+0aOWXUBIxbm\nFFQOnA9Wr0YK97wNi3M5UVvPVTdnddF87W6W/zrw9WaCsvJ56m+OBe7q8XojppfrAhTng9Wj1Sdb\na/GdsdYrHvrSNT1e5+cvHpBDJGbWmQu9NW3ne45raL2vXXl2L0diZl1xobemzf/J93u8zuKtW3nj\n1ffkEI1ZeeV1I5ULvTXtlI9MZfmrL/donc+POD6naMysMxd6a5rufZhLhp/IaSd8iGd31C7477j8\nghZEZVacRnrmeT4WwYXees32NWv52FsnsiN27nY5RYsCMitQTwp33s++caG3XrXjuS1MGjqGSaPe\n1+0yh8wq1yWVZo1q9cPLulPzOnqzRux4bgsThoym7/Aj+OU9c15rP+HST3EA9xUYmVlrZYt9V9fX\nt+I/Axd6y9X2J55kwpDR7PX2v4BV6zjgBRd523NNGDK6kMcVu9BbS+x8eHnRIZi1hSKGczxGb2ZW\ncS70ZmYV50JvZlZxLvRmZhXnQm9mVnEu9GZmFedCb2ZWcS70ZmYVV7PQSxom6deSHpX0iKRPp+0D\nJc2X9Hj6enDaLklXSVopaYmkMXkfhFkrOBesrOrp0W8HPhsRo4DxwEWSRgHTgQURMRJYkP4OMJHk\n2+5HAtOAnn/HnFl7ci5YKdUs9BGxMSIeSqdfAJYDQ4HJwOx0sdnAGen0ZOCGSNwHHCRpcK9HbtZi\nzgUrqx6N0UsaDhwH3A8MioiN6ayngEHp9FBgbWa1dWmbWWU4F6xM6i70kvYDfg5cEhHPZ+dFRAA9\n+joJSdMkLZK0aBtbe7KqWaF6OxfSbTofLDd1FXpJ/Uje2D+MiFvS5k0dH0PT181p+3pgWGb1w9O2\nXUTEzIgYGxFj+9G/0fjNWiqPXADng+WrnqtuBFwLLI+Ib2dmzQGmptNTgdsy7eekVxyMB7ZkPtaa\nlZZzwcqqnufRvwv4OLBUUscT878A/Ctws6TzgDXAmem8ucAkYCXwMnBur0ZsVhzngpVSzUIfEXcD\n6mb2yV0sH8BFTcZl1nacC1ZWvjPWzKziXOjNzCrOhd7MrOJc6M3MKs6F3sys4lzozcwqzoXezKzi\nXOjNzCrOhd7MrOJc6M3MKs6F3sys4lzozcwqzoXezKziXOjNzCrOhd7MrOJc6M3MKs6F3sys4lzo\nzcwqzoXezKziahZ6ScMk/VrSo5IekfTptP1ySeslLU5/JmXW+UdJKyU9JmlCngdg1irOBSurml8O\nDmwHPhsRD0naH3hQ0vx03nci4lvZhSWNAqYAxwJDgF9JOiYidvRm4GYFcC5YKdXs0UfExoh4KJ1+\nAVgODN3NKpOBmyJia0SsBlYC43ojWLMiOResrHo0Ri9pOHAccH/adLGkJZKuk3Rw2jYUWJtZbR1d\nJIOkaZIWSVq0ja09DtysSL2ZC+n2nA+Wm7oLvaT9gJ8Dl0TE88A1wJuB0cBG4Iqe7DgiZkbE2IgY\n24/+PVnVrFC9nQvgfLB81VXoJfUjeWP/MCJuAYiITRGxIyJ2ArP480fS9cCwzOqHp21mpedcsDJS\nROx+AUnAbOCPEXFJpn1wRGxMp/8eOD4ipkg6FvgRyZt9CLAAGLm7E1CSXgAea/Zg2tShwNNFB5GD\nIo/ryIg4rNU7bUUupNuoaj5UNReguGOrKxfquermXcDHgaWSFqdtXwDOkjQaCOAJ4HyAiHhE0s3A\noyRXKVxUx1UGj0XE2DpiKR1Ji6p4bFU9rhpakQtQ0Xyo8num3Y+tZo++JUG0+R+pGVU9tqoeVzuo\n6t+2qscF7X9svjPWzKzi2qXQzyw6gBxV9diqelztoKp/26oeF7T5sbXF0I2ZmeWnXXr0ZmaWExd6\nM7OKK7zQSzo1fbLfSknTi46np9Jb3jdLWpZpGyhpvqTH09eD03ZJuio91iWSxhQX+e7t5kmNpT+2\nduVcaE+VyIWIKOwH6AP8HjgK2Bt4GBhVZEwNHMN7gTHAskzbN4Hp6fR04N/S6UnAfwACxgP3Fx3/\nbo5rMDAmnd4fWAGMqsKxteOPc6F93y9VyIWie/TjgJURsSoiXgVuInniX2lExF3AHzs1Tya5g5L0\n9YxM+w2RuA84SNLg1kTaM9H9kxpLf2xtyrnQpu+XKuRC0YW+7qf7lcygSG+JB54CBqXTpTzeTk9q\nrNSxtZGq/v0q9X4pay4UXegrL5LPcqW9hrWLJzW+puzHZq1V9vdLmXOh6EJf1af7ber4qJa+bk7b\nS3W8XT2pkYocWxuq6t+vEu+XsudC0YV+ITBS0ghJe5N87dqcgmPqDXOAqen0VOC2TPs56Vn58cCW\nzEe/tpI+qfFaYHlEfDszq/TH1qacC236fqlELhR9NpjkDPUKkisOvlh0PA3E/2OSL5vYRjIWdx5w\nCMkjaR8HfgUMTJcVcHV6rEuBsUXHv5vjejfJR9ElwOL0Z1IVjq1df5wLxR9DN8dV+lzwIxDMzCqu\n6KEbMzPLmQu9mVnFudCbmVWcC72ZWcW50JuZVZwLvZlZxbnQm5lV3P8Hp44X4WJgdakAAAAASUVO\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STDvKGYwnZ3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}